---
title: "Statistical Rethinking (Code)"
author: "Chapter 14"
date: "May, 2017"
output:
  html_document: 
    fig_height: 3.5
  pdf_document: 
    fig_height: 3.5
---

```{r, setup, include = FALSE}
# Load packages here 
require(rethinking)
require(mosaic)   
require(ggformula)

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  cache = TRUE,
  error = TRUE,
  tidy = FALSE,     # display code as typed
  size = "small",   # slightly smaller font for code
  fig.show = "hold")   # all plots at end of chunk
theme_set(theme_light())

options(`mosaic:parallelMessage` = FALSE)
set.seed(12345)
```


Code from *Statistical Rethinking* modified by R Pruim is shown below.  Differences to the oringal include:

  * a preference for putting data into containers (data frames, mostly), rather than working with lose vectors.
  * use of `ggplot2` (via `ggformula`) rather than base graphics
  * use of `tidyverse` for data transformation
  * better (in my opinion) naming conventions


#### R code 14.1

```{r, chunk14.1}
ThreePancakes <-
  data_frame(
    id = 1:3,
    A = c(0, 0, 1),
    B = c(0, 1, 1)
  )

pancake_sample <- function(n, cakes = ThreePancakes) {
  S <- sample(cakes, size = n, replace = TRUE)
  S %>% mutate(
    up_side = ifelse(rbinom(n, 1, 0.5), "A", "B"),
    up = ifelse(up_side == "A", A, B),
    down = ifelse(up_side == "A", B, A)
  )
}

# sim 10,000 pancakes
Pancakes <- pancake_sample(n = 1e4)

head(Pancakes)

# if top is 1, what is prob that bottom is also 1
Pancakes %>%
  filter(up == 1) %>%
  summarise(n = n(), prop_down1 = sum(down) / n)
```

#### R code 14.2

```{r, chunk14.2}
data(WaffleDivorce)

gf_pointrange(
  Divorce + (Divorce - Divorce.SE) + (Divorce + Divorce.SE) ~ MedianAgeMarriage, 
  data = WaffleDivorce, alpha = .5) %>%
  gf_labs(x ="Median age marriage", y = "Divorce rate")
```

#### R code 14.3

```{r, chunk14.3}
Div2 <-
  with(WaffleDivorce,
       data_frame(
         div_obs = Divorce,
         div_sd = Divorce.SE,
         mar_obs = Marriage,
         mar_sd = Marriage.SE,
         age_obs = MedianAgeMarriage,
         population = Population,
         state = Location
       )
  ) 
```

```{r}
m14.1 <- map2stan(
  alist(
    div_est ~ dnorm(mu, sigma),
    mu <- a + bA * age_obs + bR * mar_obs,
    div_obs ~ dnorm(div_est, div_sd),
    a ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2.5)
  ),
  data = Div2, start = list(div_est = Div2$div_obs),
  WAIC = FALSE,
  iter = 5000, warmup = 1000, chains = 2, cores = 2,
  control = list(adapt_delta = 0.95), refresh = 0
)
```

#### R code 14.4

```{r, chunk14.4}
precis(m14.1, depth = 2)
```

### Figure 14.2

#### Show me the data!

We need to do a little guesswork here, because the description of the plot is missing
a couple details.  But they are easy enough to guess given the usual practices of 
the author.

  * likely the marriage rate was set to the mean or median for the counterfactual data
  * the "other model" is the one that is like `m14.1` but doesn't include estimation
  of `div_est` and just uses `div_obs`.  We'll call that model `m14.0` below.
 
The plots themeselves are easily made -- one you get the data into a handy format.
A first step for that is to figure out where the data we need for the plot 
live.  Here are some options:

  * The original data frame
  * A lightly transformed version of the origianl data frame (perhaps with new 
  variable names, missing data removed, or some additional variables calculated)
  * Counterfactual data that we create.
  * The `precis` object.
  * The results of using `link()`, `sim()` or `ensemble()`.

Sometimes these work in combination.  For example, we may create counterfactual
data and pass that along as the `data` argument to `link()` or `sim()` or 
`ensemble()`, or we might average values from one object and add them as
a new column in another.

In some cases, we also need to figure out how to extract that data from those
objects to put them into a data frame (because that's the format `ggformula`,
requires). `glimpse()` (or `str()`) can be useful for inspecting objects to see
how they are organized.

#### Obtaining information from precis output

```{r}
m14.1_precis <- precis(m14.1, depth = 2)   
glimpse(m14.1_precis)     # look at structure of the precis object
m14.1_coef <- coef(m14.1)   
glimpse(m14.1_coef)       # look at structure of the coef object
```

```{r}
Div3 <-
  Div2 %>%
  mutate(
    div_est = m14.1_precis@output$Mean[1:50],
    div_est2 = m14.1_coef[1:50],  # alternative method
    div_est_se = m14.1_precis@output$StdDev[1:50]
  )
gf_abline(slope = 1, yintercept = 0, color = "red") %>% 
  gf_point(div_est2 ~ div_est, data = Div3) %>% 
  gf_labs(title = "Two methods of extracting coefficients give identical results")
```

```{r}
gf_point( (div_est - div_obs) ~ div_sd, data = Div3)
```

#### Using counterfactual data to look at model predictions

```{r}
favstats( ~ mar_obs, data = Div3)
CounterFactualData <-
  expand.grid(age_obs = seq(23, 30, by = 0.25), mar_obs = 20)
m14.1_link <- link(m14.1, data = CounterFactualData)
CounterFactualData <- 
  CounterFactualData %>% 
  mutate(
    div_m14.1 = apply(m14.1_link, 2, mean),
    div_m14.1_lo = apply(m14.1_link, 2, PI)[1, ],
    div_m14.1_hi = apply(m14.1_link, 2, PI)[2, ]
  )
head(CounterFactualData, 3)
```


```{r}
gf_pointrange( 
  div_est + (div_est - div_est_se) + (div_est + div_est_se) ~ age_obs,
  data = Div3) %>%
  gf_ribbon(div_m14.1_lo + div_m14.1_hi ~ age_obs, data = CounterFactualData, fill = "navy") %>%
  gf_line(div_m14.1 ~ age_obs, data = CounterFactualData, color = "navy") 
```

#### The "other model"

To get the "other model", we need to fit a simpler model that doesn't estimate divorce rates.

```{r}
m14.0 <- map2stan(
  alist(
    div_obs ~ dnorm(mu, sigma),
    mu <- a + bA * age_obs + bR * mar_obs,
    a ~ dnorm(30, 20),
    bA ~ dnorm(0, 10),
    bR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2.5)
  ),
  data = Div2, 
  WAIC = FALSE, iter = 5000, warmup = 1000, chains = 2, cores = 2, refresh = 0 )
```

```{r}
m14.0_link <- link(m14.0, data = CounterFactualData)
CounterFactualData <- 
  CounterFactualData %>% 
  mutate(
    div_m14.0 = apply(m14.0_link, 2, mean),
    div_m14.0_lo = apply(m14.0_link, 2, PI)[1, ],
    div_m14.0_hi = apply(m14.0_link, 2, PI)[2, ]
  )
head(CounterFactualData, 3)
```

```{r}
gf_pointrange( 
  div_est + (div_est - div_est_se) + (div_est + div_est_se) ~ age_obs,
  data = Div3) %>%
  gf_ribbon(div_m14.1_lo + div_m14.1_hi ~ age_obs, data = CounterFactualData, fill = "navy") %>%
  gf_line(div_m14.1 ~ age_obs, data = CounterFactualData, color = "navy") %>%
  gf_ribbon(div_m14.0_lo + div_m14.0_hi ~ age_obs, data = CounterFactualData) %>%
  gf_line(div_m14.0 ~ age_obs, data = CounterFactualData, linetype = "dashed") 
```


#### R code 14.5

```{r, chunk14.5}
m14.2 <- map2stan(
  alist(
    div_est ~ dnorm(mu, sigma),
    mu <- a + bA * age_obs + bR * mar_est[i],
    div_obs ~ dnorm(div_est, div_sd),
    mar_obs ~ dnorm(mar_est, mar_sd),
    a ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2.5)
  ),
  data = Div2,
  start = list(div_est = Div2$div_obs, mar_est = Div2$mar_obs),
  WAIC = FALSE, iter = 5000, warmup = 1000, chains = 3, cores = 3,
  control = list(adapt_delta = 0.95), refresh = 0
)
```

```{r}
precis(m14.2)
```

#### Figure 14.3

This plot is easier than Figure 14.2 because we don't have to 
work with counterfactual data, so there is one less step.  We
can get everything we need from the `precis()` output.

```{r}
m14.2_precis <-  precis(m14.2, depth = 2)
Div4 <-
  Div2 %>%
  mutate(
    div_est = m14.2_precis@output$Mean[1:50],
    div_est_se = m14.2_precis@output$StdDev[1:50],
    mar_est = m14.2_precis@output$Mean[51:100],
    mar_est_se = m14.2_precis@output$StdDev[51:100]
  )
```

 
```{r}
gf_point( (mar_est - mar_obs) ~ mar_sd, data = Div4)
```

  
The version below adds an extra element not in the text.
It showing the population of the states (larger dots for 
smaller states because they have more uncertainty).  
As we can see, 

 * estimates generally move toward the average (the red dots are closer to the
 center than their associated blue dots in most cases)
 * the estimates change more when states are smaller
 
```{r}
gf_point(div_est ~ mar_est + color::"estimated" + size:population, data = Div4, alpha = 0.6) %>%
  gf_point(div_obs ~ mar_obs + color::"observed" + size:population, data = Div4, alpha = 0.6) %>%
  gf_segment(div_est + div_obs ~ mar_est + mar_obs, data = Div4, alpha = 0.5) %>%
  gf_labs(x = "marriage rate", y = "divorce rate") %>%
  gf_refine(scale_size_continuous(trans = "reciprocal"))
```

#### R code 14.6

```{r, chunk14.6}
data(milk)
Milk <- milk %>%
  mutate(
    neocortex = neocortex.perc / 100,   # proportion instead of precent
    logmass = log(mass),     # map2stan() can't compute on the fly, we have to do it in advance
    kcal = kcal.per.g        # b/c we are going to delete kcal.per.g in a moment
  ) %>% 
  select(- matches("\\."))    # avoid dots -- Stan doesn't like them
# Notice the missing values
favstats( ~ neocortex, data = Milk)
```

#### R code 14.7

```{r, chunk14.7}
# fit model
m14.3 <- map2stan(
  alist(
    kcal ~ dnorm(mu, sigma),
    mu <- a + bN * neocortex + bM * logmass,
    neocortex ~ dnorm(nu, sigma_N),
    a ~ dnorm(0, 100),
    c(bN, bM) ~ dnorm(0, 10),
    nu ~ dnorm(0.5, 1),
    sigma_N ~ dcauchy(0, 1),
    sigma ~ dcauchy(0, 1)
  ),
  data = Milk, iter = 1e4, chains = 2, refresh = 0
)

```

#### R code 14.8

```{r, chunk14.8}
precis(m14.3, depth = 2)
```

#### R code 14.9

```{r, chunk14.9}
# remove the rows with missing neocortex
Milkcc <- Milk %>% filter(!is.na(neocortex))

# fit model
m14.3cc <- map2stan(
  alist(
    kcal ~ dnorm(mu, sigma),
    mu <- a + bN * neocortex + bM * logmass,
    a ~ dnorm(0, 100),
    c(bN, bM) ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 1)
  ),
  data = Milkcc, iter = 1e4, chains = 2, refresh = 0
)
precis(m14.3cc)
```

#### R code 14.10

```{r, chunk14.10}
m14.4 <- map2stan(
  alist(
    kcal ~ dnorm(mu, sigma),
    mu <- a + bN * neocortex + bM * logmass,
    neocortex ~ dnorm(nu, sigma_N),
    nu <- a_N + gM * logmass,
    a ~ dnorm(0, 100),
    c(bN, bM, gM) ~ dnorm(0, 10),
    a_N ~ dnorm(0.5, 1),
    sigma_N ~ dcauchy(0, 1),
    sigma ~ dcauchy(0, 1)
  ),
  data = Milk,
  iter = 1e4,
  chains = 2
)
precis(m14.4, depth = 2)
```

#### R code 14.11

```{r, chunk14.11}
nc_missing <- ifelse(is.na(Milk$neocortex), 1, 0)
nc_missing <- nc_missing * cumsum(nc_missing)
nc_missing
```

#### R code 14.12

```{r, chunk14.12}
nc <- ifelse(is.na(Milk$neocortex), -1, Milk$neocortex)
nc
```

#### R code 14.13

```{r, chunk14.13}
model_code <- '
  data{
    int N;
    int nc_num_missing;
    vector[N] kcal;
    real neocortex[N];
    vector[N] logmass;
    int nc_missing[N];
  }
  parameters{
    real alpha;
    real<lower=0> sigma;
    real bN;
    real bM;
    vector[nc_num_missing] nc_impute;
    real mu_nc;
    real<lower=0> sigma_nc;
  }
  model{
    vector[N] mu;
    vector[N] nc_merged;
    alpha ~ normal(0,10);
    bN ~ normal(0,10);
    bM ~ normal(0,10);
    mu_nc ~ normal(0.5,1);
    sigma ~ cauchy(0,1);
    sigma_nc ~ cauchy(0,1);
    // merge missing and observed
    for (i in 1:N) {
      nc_merged[i] <- neocortex[i];
      if (nc_missing[i] > 0) nc_merged[i] <- nc_impute[nc_missing[i]];
    }
    // imputation
    nc_merged ~ normal(mu_nc, sigma_nc);
    // regression
    mu = alpha + bN*nc_merged + bM*logmass;
    kcal ~ normal(mu, sigma);
  }'
```

#### R code 14.14

```{r, chunk14.14}
data_list <- 
  with(Milk,
       list(
         N = nrow(Milk),
         kcal = kcal,
         neocortex = nc,
         logmass = logmass,
         nc_missing = nc_missing,
         nc_num_missing = max(nc_missing)
       )
  )
start <- list(
  alpha = mean(Milk$kcal),
  sigma = sd(Milk$kcal),
  bN = 0,
  bM = 0,
  mu_nc = 0.68,
  sigma_nc = 0.06,
  nc_impute = rep(0.5, max(nc_missing))
)
library(rstan)
m14.3stan <-
  stan(
    model_code = model_code,
    data = data_list,
    init = list(start),
    iter = 1e4,
    chains = 1
  )
```

#### R code 14.15

```{r, chunk14.15}
set.seed(100)
x <- c(rnorm(10), NA)
y <- c(rnorm(10, x), 100)
d <- list(x = x, y = y)
```


#### Doubling standard errors

This model using double the standard errors and doesn't fit efficiently.  (I don't think that 
was the point the author was looking for, but it is true.)  The "divergent iterations" warnings
indicate that at best, the model is converging slowly and at worst, it is not converging at all.

```{r}
m14.2b <- map2stan(
  alist(
    div_est ~ dnorm(mu, sigma),
    mu <- a + bA * age_obs + bR * mar_obs,
    div_obs ~ dnorm(div_est, div_sd),
    a ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2.5)
  ),
  data = Div2 %>% mutate(div_sd = 2 * div_sd, mar_sd = 2 * mar_sd),
  start = list(div_est = Div2$div_obs),
  WAIC = FALSE, iter = 500, warmup = 100, chains = 4, cores = 2,
  control = list(adapt_delta = 0.99), refresh = 0
)
```

```{r}
plot(m14.2b)
traceplot(m14.2b@stanfit)
```